{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e46b78bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定图片路径\n",
    "image_path = 'F:\\\\JupyterWorkSpace\\\\BBBBBBS\\\\train\\\\c4\\\\img_14.jpg'  # 请确保这条路径是有效的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6efca99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Test =====\n",
      "Predicting for image: F:/JupyterWorkSpace/BBBBBBS/train/c1/img_115.jpg\n",
      "1/1 [==============================] - 1s 739ms/step\n",
      "Prediction result: (1, 2048)\n",
      "Begin creating database for ResNet50\n",
      "write_gap_test ResNet50 succeeded\n",
      "Predicting for image: F:/JupyterWorkSpace/BBBBBBS/train/c1/img_115.jpg\n",
      "1/1 [==============================] - 1s 571ms/step\n",
      "Prediction result: (1, 2048)\n",
      "Begin creating database for Xception\n",
      "write_gap_test Xception succeeded\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Lambda, GlobalAveragePooling2D\n",
    "from keras.applications import ResNet50, Xception, InceptionV3\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing import image  # 使用 tensorflow.keras\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_v3_preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input as xception_preprocess_input\n",
    "\n",
    "def load_custom_model(MODEL, weight_file, image_size):\n",
    "    # 输入张量\n",
    "    input_tensor = Input((*image_size, 3))\n",
    "    base_model = MODEL(input_tensor=input_tensor, weights=None, include_top=False)\n",
    "    \n",
    "    # 加载权重\n",
    "    base_model.load_weights(\"models/\" + weight_file, by_name=True)\n",
    "    \n",
    "    # 构建最终模型\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def write_gap_test(tag, MODEL, weight_file, image_size, image_path, lambda_func=None, featurewise_std_normalization=True):\n",
    "    # 检查图片路径是否有效\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # 加载自定义模型\n",
    "    model = load_custom_model(MODEL, weight_file, image_size)\n",
    "    \n",
    "    print(f\"Predicting for image: {image_path}\")\n",
    "    \n",
    "    # 直接加载和预处理单张图片\n",
    "    img = image.load_img(image_path, target_size=image_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # 增加batch维度\n",
    "    \n",
    "    # 使用lambda函数进行预处理\n",
    "    if lambda_func:\n",
    "        img_array = lambda_func(img_array)\n",
    "    elif featurewise_std_normalization:\n",
    "        img_array = img_array / 255.0  # 假设图片值已归一化\n",
    "    \n",
    "    # 进行预测\n",
    "    test = model.predict(img_array)\n",
    "    print(\"Prediction result: {}\".format(test.shape))\n",
    "\n",
    "    # 将预测结果保存到文件\n",
    "    output_dir = os.path.join(\"models\", tag)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(f\"Begin creating database for {MODEL.__name__}\")\n",
    "    with h5py.File(os.path.join(output_dir, f\"bottleneck_{MODEL.__name__}_test.h5\"), 'w') as h:\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "    \n",
    "    print(f\"write_gap_test {MODEL.__name__} succeeded\")\n",
    "\n",
    "# 测试不同模型时指定的图片路径\n",
    "# image_path = 'F:/JupyterWorkSpace/BBBBBBS/train/c1/img_115.jpg'  # 确保这条路径是有效的\n",
    "\n",
    "resnet50_weight_file = \"resnet50-imagenet-finetune152.h5\"\n",
    "xception_weight_file = \"xception-imagenet-finetune116.h5\"\n",
    "inceptionV3_weight_file = \"inceptionV3-imagenet-finetune172.h5\"\n",
    "\n",
    "print(\"===== Test =====\")\n",
    "write_gap_test(\"Single\", ResNet50, resnet50_weight_file, (240, 320), image_path)\n",
    "write_gap_test(\"Single\", Xception, xception_weight_file, (320, 480), image_path, xception_preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4830cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for image: F:/JupyterWorkSpace/BBBBBBS/train/c1/img_115.jpg\n",
      "1/1 [==============================] - 1s 811ms/step\n",
      "Prediction result: (1, 2048)\n",
      "Begin creating database for InceptionV3\n",
      "write_gap_test InceptionV3 succeeded\n"
     ]
    }
   ],
   "source": [
    "# 需要运行两次\n",
    "write_gap_test(\"Single\", InceptionV3, inceptionV3_weight_file, (320, 480), image_path, inception_v3_preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddf76e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Clipped Prediction: [[0.07775538 0.08730915 0.10445213 0.14501858 0.17224728 0.07249112\n",
      "  0.08881389 0.07735401 0.0904341  0.08412421]]\n",
      "------y_pred--------\n",
      "[[0.07775538 0.08730915 0.10445213 0.14501858 0.17224728 0.07249112\n",
      "  0.08881389 0.07735401 0.0904341  0.08412421]]\n",
      "Predicted class: c4, Probability: 0.1722472757101059\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import h5py\n",
    "\n",
    "def extract_features_from_models(test_premodels, image_path, model_image_size):\n",
    "    \"\"\"\n",
    "    Extract features for a single image from multiple pre-trained models.\n",
    "    \n",
    "    Args:\n",
    "        test_premodels: List of pre-trained model file paths.\n",
    "        image_path: Path to the image for prediction.\n",
    "        model_image_size: Target size for image resizing.\n",
    "    \n",
    "    Returns:\n",
    "        X_test: Extracted features from all pre-trained models.\n",
    "    \"\"\"\n",
    "    X_test = []\n",
    "    \n",
    "    # 加载并预处理图像\n",
    "    img = load_img(image_path, target_size=(model_image_size, model_image_size))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # 增加批量维度\n",
    "\n",
    "    # 从每个预训练模型中提取特征\n",
    "    for model_file in test_premodels:\n",
    "        with h5py.File(model_file, 'r') as h:\n",
    "            features = np.array(h['test'])  # 提取预训练模型的特征\n",
    "            X_test.append(features)\n",
    "\n",
    "    # 合并所有特征\n",
    "    X_test = np.concatenate(X_test, axis=1)\n",
    "    return X_test\n",
    "\n",
    "def predict_with_mixed_model(model, X_test):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image using the mixed model and extracted features.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained mixed model.\n",
    "        X_test: Features extracted from pre-trained models.\n",
    "    \"\"\"\n",
    "    # 使用混合模型进行预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    # print(f\"Prediction: {y_pred}\")\n",
    "    \n",
    "    # 裁剪预测结果，确保在合理范围内\n",
    "    y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "    print(f\"Clipped Prediction: {y_pred}\")\n",
    "    \n",
    "    print(\"------y_pred--------\")\n",
    "    print(y_pred)\n",
    "    # 将 y_pred 扁平化为一维数组\n",
    "    y_pred = y_pred.flatten()\n",
    "    # 使用 np.argmax 找到最大概率值的索引\n",
    "    predicted_class = np.argmax(y_pred)\n",
    "    # 获取最大预测类别的概率值\n",
    "    predicted_prob = y_pred[predicted_class]\n",
    "    # 打印出预测的类别索引及其概率值\n",
    "    print(f\"Predicted class: c{predicted_class}, Probability: {predicted_prob}\")\n",
    "\n",
    "# 加载混合模型\n",
    "model_mix = load_model(\"models/mixed-model.h5\")\n",
    "\n",
    "# 预训练模型文件路径\n",
    "test_premodels = [\n",
    "    \"models/Single/bottleneck_ResNet50_test.h5\",\n",
    "    \"models/Single/bottleneck_Xception_test.h5\",\n",
    "    \"models/Single/bottleneck_InceptionV3_test.h5\"\n",
    "]\n",
    "\n",
    "\n",
    "# 从预训练模型中提取特征\n",
    "X_test = extract_features_from_models(test_premodels, image_path, 320)\n",
    "\n",
    "# 使用混合模型进行预测\n",
    "predict_with_mixed_model(model_mix, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea0238",
   "metadata": {},
   "source": [
    "# 汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9914d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Test =====\n",
      "Predicting for image: F:\\JupyterWorkSpace\\BBBBBBS\\train\\c1\\img_6.jpg\n",
      "1/1 [==============================] - 1s 657ms/step\n",
      "Prediction result: (1, 2048)\n",
      "Begin creating database for ResNet50\n",
      "write_gap_test ResNet50 succeeded\n",
      "Predicting for image: F:\\JupyterWorkSpace\\BBBBBBS\\train\\c1\\img_6.jpg\n",
      "1/1 [==============================] - 1s 827ms/step\n",
      "Prediction result: (1, 2048)\n",
      "Begin creating database for Xception\n",
      "write_gap_test Xception succeeded\n",
      "Predicting for image: F:\\JupyterWorkSpace\\BBBBBBS\\train\\c1\\img_6.jpg\n",
      "1/1 [==============================] - 1s 832ms/step\n",
      "Prediction result: (1, 2048)\n",
      "Begin creating database for InceptionV3\n",
      "write_gap_test InceptionV3 succeeded\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Clipped Prediction: [[0.09167638 0.08623686 0.08171918 0.152598   0.14745556 0.08306389\n",
      "  0.15198664 0.04982068 0.0744195  0.08102331]]\n",
      "------y_pred--------\n",
      "[[0.09167638 0.08623686 0.08171918 0.152598   0.14745556 0.08306389\n",
      "  0.15198664 0.04982068 0.0744195  0.08102331]]\n",
      "Predicted class: c3, Probability: 0.15259799361228943\n",
      "F:\\JupyterWorkSpace\\BBBBBBS\\train\\c1\\img_6.jpg\n"
     ]
    }
   ],
   "source": [
    "# 指定图片路径\n",
    "image_path = 'F:\\\\JupyterWorkSpace\\\\BBBBBBS\\\\test\\\\default_class\\\\img_2.jpg'  # 请确保这条路径是有效的\n",
    "image_path = 'F:\\\\JupyterWorkSpace\\\\BBBBBBS\\\\train\\\\c1\\\\img_6.jpg'  # 请确保这条路径是有效的\n",
    "\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Lambda, GlobalAveragePooling2D\n",
    "from keras.applications import ResNet50, Xception, InceptionV3\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing import image  # 使用 tensorflow.keras\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_v3_preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input as xception_preprocess_input\n",
    "\n",
    "def load_custom_model(MODEL, weight_file, image_size):\n",
    "    # 输入张量\n",
    "    input_tensor = Input((*image_size, 3))\n",
    "    base_model = MODEL(input_tensor=input_tensor, weights=None, include_top=False)\n",
    "    \n",
    "    # 加载权重\n",
    "    base_model.load_weights(\"models/\" + weight_file, by_name=True)\n",
    "    \n",
    "    # 构建最终模型\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def write_gap_test(tag, MODEL, weight_file, image_size, image_path, lambda_func=None, featurewise_std_normalization=True):\n",
    "    # 检查图片路径是否有效\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # 加载自定义模型\n",
    "    model = load_custom_model(MODEL, weight_file, image_size)\n",
    "    \n",
    "    print(f\"Predicting for image: {image_path}\")\n",
    "    \n",
    "    # 直接加载和预处理单张图片\n",
    "    img = image.load_img(image_path, target_size=image_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # 增加batch维度\n",
    "    \n",
    "    # 使用lambda函数进行预处理\n",
    "    if lambda_func:\n",
    "        img_array = lambda_func(img_array)\n",
    "    elif featurewise_std_normalization:\n",
    "        img_array = img_array / 255.0  # 假设图片值已归一化\n",
    "    \n",
    "    # 进行预测\n",
    "    test = model.predict(img_array)\n",
    "    print(\"Prediction result: {}\".format(test.shape))\n",
    "\n",
    "    # 将预测结果保存到文件\n",
    "    output_dir = os.path.join(\"models\", tag)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(f\"Begin creating database for {MODEL.__name__}\")\n",
    "    with h5py.File(os.path.join(output_dir, f\"bottleneck_{MODEL.__name__}_test.h5\"), 'w') as h:\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "    \n",
    "    print(f\"write_gap_test {MODEL.__name__} succeeded\")\n",
    "\n",
    "resnet50_weight_file = \"resnet50-imagenet-finetune152.h5\"\n",
    "xception_weight_file = \"xception-imagenet-finetune116.h5\"\n",
    "inceptionV3_weight_file = \"inceptionV3-imagenet-finetune172.h5\"\n",
    "\n",
    "print(\"===== Test =====\")\n",
    "write_gap_test(\"Single\", ResNet50, resnet50_weight_file, (240, 320), image_path)\n",
    "write_gap_test(\"Single\", Xception, xception_weight_file, (320, 480), image_path, xception_preprocess_input)\n",
    "# 需要运行两次\n",
    "write_gap_test(\"Single\", InceptionV3, inceptionV3_weight_file, (320, 480), image_path, inception_v3_preprocess_input)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import h5py\n",
    "\n",
    "def extract_features_from_models(test_premodels, image_path, model_image_size):\n",
    "    \"\"\"\n",
    "    Extract features for a single image from multiple pre-trained models.\n",
    "    \n",
    "    Args:\n",
    "        test_premodels: List of pre-trained model file paths.\n",
    "        image_path: Path to the image for prediction.\n",
    "        model_image_size: Target size for image resizing.\n",
    "    \n",
    "    Returns:\n",
    "        X_test: Extracted features from all pre-trained models.\n",
    "    \"\"\"\n",
    "    X_test = []\n",
    "    \n",
    "    # 加载并预处理图像\n",
    "    img = load_img(image_path, target_size=(model_image_size, model_image_size))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # 增加批量维度\n",
    "\n",
    "    # 从每个预训练模型中提取特征\n",
    "    for model_file in test_premodels:\n",
    "        with h5py.File(model_file, 'r') as h:\n",
    "            features = np.array(h['test'])  # 提取预训练模型的特征\n",
    "            X_test.append(features)\n",
    "\n",
    "    # 合并所有特征\n",
    "    X_test = np.concatenate(X_test, axis=1)\n",
    "    return X_test\n",
    "\n",
    "def predict_with_mixed_model(model, X_test):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image using the mixed model and extracted features.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained mixed model.\n",
    "        X_test: Features extracted from pre-trained models.\n",
    "    \"\"\"\n",
    "    # 使用混合模型进行预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    # print(f\"Prediction: {y_pred}\")\n",
    "    \n",
    "    # 裁剪预测结果，确保在合理范围内\n",
    "    y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "    print(f\"Clipped Prediction: {y_pred}\")\n",
    "    \n",
    "    print(\"------y_pred--------\")\n",
    "    print(y_pred)\n",
    "    # 将 y_pred 扁平化为一维数组\n",
    "    y_pred = y_pred.flatten()\n",
    "    # 使用 np.argmax 找到最大概率值的索引\n",
    "    predicted_class = np.argmax(y_pred)\n",
    "    # 获取最大预测类别的概率值\n",
    "    predicted_prob = y_pred[predicted_class]\n",
    "    # 打印出预测的类别索引及其概率值\n",
    "    print(f\"Predicted class: c{predicted_class}, Probability: {predicted_prob}\")\n",
    "\n",
    "# 加载混合模型\n",
    "model_mix = load_model(\"models/mixed-model.h5\")\n",
    "\n",
    "# 预训练模型文件路径\n",
    "test_premodels = [\n",
    "    \"models/Single/bottleneck_ResNet50_test.h5\",\n",
    "    \"models/Single/bottleneck_Xception_test.h5\",\n",
    "    \"models/Single/bottleneck_InceptionV3_test.h5\"\n",
    "]\n",
    "\n",
    "\n",
    "# 从预训练模型中提取特征\n",
    "X_test = extract_features_from_models(test_premodels, image_path, 320)\n",
    "\n",
    "# 使用混合模型进行预测\n",
    "predict_with_mixed_model(model_mix, X_test)\n",
    "print(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
