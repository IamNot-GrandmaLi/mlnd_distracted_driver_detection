{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c43b4b",
   "metadata": {},
   "source": [
    "# 生成混合模型的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e877f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_v3_preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input as xception_preprocess_input\n",
    "# from keras.applications.resnet50 import ResNet50, preprocess_input as resnet50_preprocess_input\n",
    "\n",
    "\n",
    "import h5py\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dbd6ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir = \"/ext/Data/distracted_driver_detection/\"\n",
    "dir = \"E:\\\\JupyterWorkSpace\\\\BBBBBBS\"\n",
    "\n",
    "resnet50_weight_file = \"resnet50-imagenet-finetune152.h5\"\n",
    "xception_weight_file = \"xception-imagenet-finetune116.h5\"\n",
    "inceptionV3_weight_file = \"inceptionV3-imagenet-finetune172.h5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1497c97",
   "metadata": {},
   "source": [
    "### 正常过程输出？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "23ef91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_preprocess_input(x):\n",
    "    x /= 255.\n",
    "    x -= 0.5\n",
    "    x *= 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa134600",
   "metadata": {},
   "source": [
    "### 训练集，验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "44ec8cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_gap(tag, MODEL, weight_file, image_size, lambda_func=None, featurewise_std_normalization=True):\n",
    "    input_tensor = Input((*image_size, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    base_model = MODEL(input_tensor=x, weights=None, include_top=False)\n",
    "\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "    model.load_weights(os.path.join(\"models\", weight_file), by_name=True)\n",
    "\n",
    "    print(MODEL.__name__)\n",
    "    train_gen = ImageDataGenerator(\n",
    "        featurewise_std_normalization=featurewise_std_normalization,\n",
    "        samplewise_std_normalization=False,\n",
    "        rotation_range=10.,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "    )\n",
    "    gen = ImageDataGenerator(\n",
    "        featurewise_std_normalization=featurewise_std_normalization,\n",
    "        samplewise_std_normalization=False,\n",
    "    )\n",
    "\n",
    "    batch_size = 64\n",
    "    train_generator = train_gen.flow_from_directory(os.path.join(dir, 'train'), target_size=image_size, shuffle=False, batch_size=batch_size)\n",
    "    print(\"subdior to train type {}\".format(train_generator.class_indices))\n",
    "    valid_generator = gen.flow_from_directory(os.path.join(dir, 'valid'), target_size=image_size, shuffle=False, batch_size=batch_size)\n",
    "    print(\"subdior to valid type {}\".format(valid_generator.class_indices))\n",
    "\n",
    "    print(\"predict_generator train {}\".format(math.ceil(train_generator.samples // batch_size + 1)))\n",
    "    train = model.predict(train_generator, steps=math.ceil(train_generator.samples // batch_size + 1))\n",
    "    print(\"train: {}\".format(train.shape))\n",
    "    print(\"predict_generator valid {}\".format(math.ceil(valid_generator.samples // batch_size + 1)))\n",
    "    valid = model.predict(valid_generator, steps=math.ceil(valid_generator.samples // batch_size + 1))\n",
    "    print(\"valid: {}\".format(valid.shape))\n",
    "\n",
    "    print(\"begin create database {}\".format(MODEL.__name__))\n",
    "    with h5py.File(os.path.join(\"models\", tag, \"bottleneck_{}.h5\".format(MODEL.__name__)), 'w') as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"valid\", data=valid)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "        h.create_dataset(\"valid_label\", data=valid_generator.classes)\n",
    "    print(\"Data saved to bottleneck_{}.h5 successfully.\".format(MODEL.__name__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e8803",
   "metadata": {},
   "source": [
    "### 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6683f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_gap_test(tag, MODEL, weight_file, image_size, lambda_func=None, featurewise_std_normalization=True):\n",
    "    # 输入张量\n",
    "    input_tensor = Input((*image_size, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)  # 使用lambda函数进行额外的预处理\n",
    "    # 加载基本模型，不包括顶部的全连接层\n",
    "    base_model = MODEL(input_tensor=x, weights=None, include_top=False)\n",
    "    # 构建最终的模型，使用全局平均池化\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "    # 加载权重文件\n",
    "    model.load_weights(\"models/\" + weight_file, by_name=True)\n",
    "\n",
    "    print(MODEL.__name__)\n",
    "    \n",
    "    # 定义测试数据的生成器\n",
    "    gen = ImageDataGenerator(\n",
    "        featurewise_std_normalization=featurewise_std_normalization,\n",
    "        samplewise_std_normalization=False,\n",
    "    )\n",
    "    \n",
    "    batch_size = 64\n",
    "    # 加载测试数据\n",
    "    test_generator = gen.flow_from_directory(\n",
    "        os.path.join(dir, 'test'),\n",
    "        target_size=image_size,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None  # 不使用标签\n",
    "    )\n",
    "    \n",
    "    print(\"predict_generator test {}\".format(math.ceil(test_generator.samples // batch_size + 1)))\n",
    "    \n",
    "    # 预测测试数据\n",
    "    test = model.predict(test_generator, steps=math.ceil(test_generator.samples // batch_size + 1))\n",
    "    print(\"test: {}\".format(test.shape))\n",
    "\n",
    "    # 将预测结果保存到文件\n",
    "    print(\"begin create database {}\".format(MODEL.__name__))\n",
    "    with h5py.File(os.path.join(\"models\", tag, \"bottleneck_{}_test.h5\".format(MODEL.__name__)),'w') as h:\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "    \n",
    "    print(\"write_gap_test {} succeeded\".format(MODEL.__name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb871668",
   "metadata": {},
   "source": [
    "### 函数调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5611ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### subdir = noscale\n",
    "###\n",
    "tag = \"finetune\"\n",
    "print(\"===== Train & Valid =====\")\n",
    "write_gap(tag, ResNet50, resnet50_weight_file, (240, 320))\n",
    "write_gap(tag, Xception, xception_weight_file, (320, 480), xception_preprocess_input)\n",
    "write_gap(tag, InceptionV3, inceptionV3_weight_file, (320, 480), inception_v3_preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9a4b8d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Test =====\n",
      "ResNet50\n",
      "Found 79726 images belonging to 1 classes.\n",
      "predict_generator test 1246\n",
      "1246/1246 [==============================] - 3746s 3s/step\n",
      "test: (79726, 2048)\n",
      "begin create database ResNet50\n",
      "write_gap_test ResNet50 succeeded\n",
      "Xception\n",
      "Found 79726 images belonging to 1 classes.\n",
      "predict_generator test 1246\n",
      "1246/1246 [==============================] - 6479s 5s/step\n",
      "test: (79726, 2048)\n",
      "begin create database Xception\n",
      "write_gap_test Xception succeeded\n",
      "InceptionV3\n",
      "Found 79726 images belonging to 1 classes.\n",
      "predict_generator test 1246\n",
      "1246/1246 [==============================] - 3549s 3s/step\n",
      "test: (79726, 2048)\n",
      "begin create database InceptionV3\n",
      "write_gap_test InceptionV3 succeeded\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Test =====\")\n",
    "write_gap_test(tag, ResNet50, resnet50_weight_file, (240, 320))\n",
    "write_gap_test(tag, Xception, xception_weight_file, (320, 480), xception_preprocess_input)\n",
    "write_gap_test(tag, InceptionV3, inceptionV3_weight_file, (320, 480), inception_v3_preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deecb4e",
   "metadata": {},
   "source": [
    "# 自己测试用的，用于改正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "446aa594",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_func=None\n",
    "tag = \"finetune\"\n",
    "MODEL = ResNet50\n",
    "MODEL1 = Xception\n",
    "MODEL2 = InceptionV3\n",
    "\n",
    "weight_file = resnet50_weight_file\n",
    "weight_file1 = xception_weight_file\n",
    "weight_file2= inceptionV3_weight_file\n",
    "\n",
    "image_size = (240, 320)\n",
    "image_size1 = (320, 480)\n",
    "image_size2 = (320, 480)\n",
    "\n",
    "featurewise_std_normalization=True\n",
    "featurewise_std_normalization1=xception_preprocess_input\n",
    "featurewise_std_normalization2=inception_v3_preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1944b5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50\n",
      "Found 20787 images belonging to 10 classes.\n",
      "subdior to train type {'c0': 0, 'c1': 1, 'c2': 2, 'c3': 3, 'c4': 4, 'c5': 5, 'c6': 6, 'c7': 7, 'c8': 8, 'c9': 9}\n",
      "Found 1637 images belonging to 10 classes.\n",
      "subdior to valid type {'c0': 0, 'c1': 1, 'c2': 2, 'c3': 3, 'c4': 4, 'c5': 5, 'c6': 6, 'c7': 7, 'c8': 8, 'c9': 9}\n",
      "predict_generator train 325\n",
      "325/325 [==============================] - 991s 3s/step\n",
      "train: (20787, 2048)\n",
      "predict_generator valid 26\n",
      "26/26 [==============================] - 76s 3s/step\n",
      "valid: (1637, 2048)\n"
     ]
    }
   ],
   "source": [
    "# 模型加载权重文件：ResNet50\n",
    "input_tensor = Input((*image_size, 3))\n",
    "x = input_tensor\n",
    "if lambda_func:\n",
    "    x = Lambda(lambda_func)(x)\n",
    "base_model = MODEL(input_tensor=x, weights=None, include_top=False)\n",
    "model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "model.load_weights(os.path.join(\"models\", weight_file), by_name=True)\n",
    "\n",
    "# 当前模型\n",
    "print(MODEL.__name__)\n",
    "# 训练数据 生成器\n",
    "train_gen = ImageDataGenerator(\n",
    "    featurewise_std_normalization=featurewise_std_normalization,\n",
    "    samplewise_std_normalization=False,\n",
    "    rotation_range=10.,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "gen = ImageDataGenerator(\n",
    "    featurewise_std_normalization=featurewise_std_normalization,\n",
    "    samplewise_std_normalization=False,\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "# 加载训练数据\n",
    "train_generator = train_gen.flow_from_directory(os.path.join(dir, 'train'), target_size=image_size, shuffle=False, batch_size=batch_size)\n",
    "print(\"subdior to train type {}\".format(train_generator.class_indices))\n",
    "# 加载验证数据\n",
    "valid_generator = gen.flow_from_directory(os.path.join(dir, 'valid'), target_size=image_size, shuffle=False, batch_size=batch_size)\n",
    "print(\"subdior to valid type {}\".format(valid_generator.class_indices))\n",
    "\n",
    "# 预测训练数据\n",
    "print(\"predict_generator train {}\".format(math.ceil(train_generator.samples // batch_size + 1)))\n",
    "train = model.predict(train_generator, steps=math.ceil(train_generator.samples // batch_size + 1))\n",
    "print(\"train: {}\".format(train.shape))\n",
    "# 预测测试数据\n",
    "print(\"predict_generator valid {}\".format(math.ceil(valid_generator.samples // batch_size + 1)))\n",
    "valid = model.predict(valid_generator, steps=math.ceil(valid_generator.samples // batch_size + 1))\n",
    "print(\"valid: {}\".format(valid.shape))\n",
    "\n",
    "# 数据存储在train、valid、train_generator、valid_generator 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "955c116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to bottleneck_ResNet50.h5 successfully.\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(os.path.join(\"models\", tag, \"bottleneck_{}.h5\".format(MODEL.__name__)), 'w') as h:\n",
    "    h.create_dataset(\"train\", data=train)\n",
    "    h.create_dataset(\"valid\", data=valid)\n",
    "    h.create_dataset(\"label\", data=train_generator.classes)\n",
    "    h.create_dataset(\"valid_label\", data=valid_generator.classes)\n",
    "print(\"Data saved to bottleneck_{}.h5 successfully.\".format(MODEL.__name__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d574b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3\n",
      "Found 20787 images belonging to 10 classes.\n",
      "subdior to train type {'c0': 0, 'c1': 1, 'c2': 2, 'c3': 3, 'c4': 4, 'c5': 5, 'c6': 6, 'c7': 7, 'c8': 8, 'c9': 9}\n",
      "Found 1637 images belonging to 10 classes.\n",
      "subdior to valid type {'c0': 0, 'c1': 1, 'c2': 2, 'c3': 3, 'c4': 4, 'c5': 5, 'c6': 6, 'c7': 7, 'c8': 8, 'c9': 9}\n",
      "predict_generator train 325\n",
      "325/325 [==============================] - 1892s 6s/step\n",
      "train: (20787, 2048)\n",
      "predict_generator valid 26\n",
      "26/26 [==============================] - 146s 6s/step\n",
      "valid: (1637, 2048)\n"
     ]
    }
   ],
   "source": [
    "# 模型加载权重文件：InceptionV3\n",
    "input_tensor2 = Input((*image_size2, 3))\n",
    "x2 = input_tensor2\n",
    "if lambda_func:\n",
    "    x = Lambda(lambda_func)(x)\n",
    "base_model2 = MODEL2(input_tensor=x, weights=None, include_top=False)\n",
    "model2 = Model(base_model2.input, GlobalAveragePooling2D()(base_model2.output))\n",
    "model2.load_weights(os.path.join(\"models\", weight_file2), by_name=True)\n",
    "\n",
    "# 当前模型\n",
    "print(MODEL2.__name__)\n",
    "# 训练数据 生成器\n",
    "train_gen2 = ImageDataGenerator(\n",
    "    featurewise_std_normalization=featurewise_std_normalization2,\n",
    "    samplewise_std_normalization=False,\n",
    "    rotation_range=10.,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "gen2 = ImageDataGenerator(\n",
    "    featurewise_std_normalization=featurewise_std_normalization2,\n",
    "    samplewise_std_normalization=False,\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "# 加载训练数据\n",
    "train_generator2 = train_gen2.flow_from_directory(os.path.join(dir, 'train'), target_size=image_size2, shuffle=False, batch_size=batch_size)\n",
    "print(\"subdior to train type {}\".format(train_generator2.class_indices))\n",
    "# 加载验证数据\n",
    "valid_generator2 = gen2.flow_from_directory(os.path.join(dir, 'valid'), target_size=image_size2, shuffle=False, batch_size=batch_size)\n",
    "print(\"subdior to valid type {}\".format(valid_generator2.class_indices))\n",
    "\n",
    "# 预测训练数据\n",
    "print(\"predict_generator train {}\".format(math.ceil(train_generator2.samples // batch_size + 1)))\n",
    "train2 = model.predict(train_generator2, steps=math.ceil(train_generator2.samples // batch_size + 1))\n",
    "print(\"train: {}\".format(train.shape))\n",
    "# 预测测试数据\n",
    "print(\"predict_generator valid {}\".format(math.ceil(valid_generator2.samples // batch_size + 1)))\n",
    "valid2 = model.predict(valid_generator2, steps=math.ceil(valid_generator2.samples // batch_size + 1))\n",
    "print(\"valid: {}\".format(valid.shape))\n",
    "\n",
    "# 数据存储在train、valid、train_generator、valid_generator 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abe16ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to bottleneck_InceptionV3.h5 successfully.\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(os.path.join(\"models\", tag, \"bottleneck_{}.h5\".format(MODEL2.__name__)), 'w') as h2:\n",
    "    h2.create_dataset(\"train\", data=train2)\n",
    "    h2.create_dataset(\"valid\", data=valid2)\n",
    "    h2.create_dataset(\"label\", data=train_generator2.classes)\n",
    "    h2.create_dataset(\"valid_label\", data=valid_generator2.classes)\n",
    "print(\"Data saved to bottleneck_{}.h5 successfully.\".format(MODEL2.__name__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84084fe7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys only in file1: set()\n",
      "Keys only in file2: set()\n",
      "Difference found in dataset: valid\n",
      "File1 valid:\n",
      " [[0.2246282  0.09479816 0.22710085 ... 0.69714415 0.15253998 0.19852418]\n",
      " [0.12403081 0.49175826 0.13511154 ... 0.35331428 0.10390443 0.21329199]\n",
      " [0.19812007 0.33401868 0.1574735  ... 0.32233372 0.12638298 0.2093997 ]\n",
      " ...\n",
      " [0.34972832 0.6115425  0.36129025 ... 0.36448795 0.08421514 0.14278704]\n",
      " [0.27985427 0.5858992  0.32419595 ... 0.3996869  0.23800059 0.07301176]\n",
      " [0.59768915 0.10676511 0.09687085 ... 0.41471806 0.5666444  0.36041027]]\n",
      "File2 valid:\n",
      " [[0.4789863  0.06350634 0.29304647 ... 0.01331133 0.13000038 0.05837492]\n",
      " [0.36633962 0.22098663 0.2565125  ... 0.07923584 0.08195297 0.10843932]\n",
      " [0.41572216 0.4418104  0.47690684 ... 0.05978933 0.149256   0.0111434 ]\n",
      " ...\n",
      " [0.09337121 0.4757786  0.11805671 ... 0.14525647 0.18383819 0.1445847 ]\n",
      " [0.08573153 0.38129157 0.15797186 ... 0.26685232 0.15418164 0.10451419]\n",
      " [0.51839924 0.27710393 0.2490445  ... 0.04606501 0.07823636 0.0414037 ]]\n",
      "Difference found in dataset: train\n",
      "File1 train:\n",
      " [[0.12362273 0.34347352 0.11629581 ... 0.68784904 0.24357371 0.55924076]\n",
      " [0.06252602 0.18236667 0.1041818  ... 0.1106841  0.03553814 0.32109216]\n",
      " [0.12068638 0.3267537  0.1892529  ... 0.40358093 0.0662964  0.13991512]\n",
      " ...\n",
      " [0.09253304 0.41040573 0.01867357 ... 0.40995398 0.70436627 0.08700113]\n",
      " [0.05633765 0.05748872 0.04922857 ... 0.24733557 0.36360627 0.20951839]\n",
      " [0.12057524 0.26415023 0.00978181 ... 0.5431309  0.34617305 0.66437685]]\n",
      "File2 train:\n",
      " [[9.0663826e-01 1.4120089e-01 6.2241638e-01 ... 2.8547585e-02\n",
      "  1.0384147e-01 4.7640293e-03]\n",
      " [3.0736592e-01 3.9943434e-02 2.4709393e-01 ... 6.6611193e-02\n",
      "  1.5359044e-04 0.0000000e+00]\n",
      " [9.6173227e-01 9.0638615e-02 6.4366966e-01 ... 0.0000000e+00\n",
      "  1.5644180e-02 9.1651632e-03]\n",
      " ...\n",
      " [7.0484543e-01 7.8615546e-01 3.0358779e-01 ... 4.4795368e-02\n",
      "  5.7668658e-03 1.2244383e-04]\n",
      " [6.8848258e-01 6.8908882e-01 5.4346228e-01 ... 4.7055714e-02\n",
      "  1.3930519e-03 1.8789778e-02]\n",
      " [6.7679060e-01 4.8447582e-01 7.3779516e-02 ... 1.0367993e-01\n",
      "  7.3253788e-04 3.9268088e-02]]\n",
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "比较h5文件的差异\n",
    "\"\"\"\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def compare_h5(file1, file2):\n",
    "    with h5py.File(os.path.join(\"models\", tag, file1), 'r') as f1,h5py.File(os.path.join(\"models\", tag, file2), 'r') as f2:\n",
    "        # 比较文件中的所有键（数据集/属性）\n",
    "        keys1 = set(f1.keys())\n",
    "        keys2 = set(f2.keys())\n",
    "        \n",
    "        # 打印差异\n",
    "        print(\"Keys only in file1:\", keys1 - keys2)\n",
    "        print(\"Keys only in file2:\", keys2 - keys1)\n",
    "        i = 0\n",
    "        j=0\n",
    "        # 比较每个数据集的内容\n",
    "        for key in keys1 & keys2:\n",
    "            j+=1\n",
    "            dataset1 = f1[key][...]\n",
    "            dataset2 = f2[key][...]\n",
    "#             print(\"dataset1\",dataset1)\n",
    "#             print(\"dataset2\",dataset2)\n",
    "\n",
    "            if not (dataset1 == dataset2).all():\n",
    "                i+=1\n",
    "                print(f\"Difference found in dataset: {key}\")\n",
    "                print(f\"File1 {key}:\\n\", dataset1)\n",
    "                print(f\"File2 {key}:\\n\", dataset2)\n",
    "        \n",
    "        print(j)\n",
    "        print(i)\n",
    "compare_h5('bottleneck_InceptionV3.h5', 'bottleneck_Xception.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1071ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "对生成test模型的测试,失败\n",
    "\"\"\"\n",
    "def write_gap_test(tag, MODEL, weight_file, image_size, lambda_func=None, featurewise_std_normalization=True):\n",
    "    # 输入张量\n",
    "    input_tensor = Input((*image_size, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)  # 使用lambda函数进行额外的预处理\n",
    "    # 加载基本模型，不包括顶部的全连接层\n",
    "    base_model = MODEL(input_tensor=x, weights=None, include_top=False)\n",
    "    # 构建最终的模型，使用全局平均池化\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "    # 加载权重文件\n",
    "    model.load_weights(\"models/\" + weight_file, by_name=True)\n",
    "\n",
    "    print(MODEL.__name__)\n",
    "    \n",
    "    # 定义测试数据的生成器\n",
    "    gen = ImageDataGenerator(\n",
    "        featurewise_std_normalization=featurewise_std_normalization,\n",
    "        samplewise_std_normalization=False,\n",
    "    )\n",
    "    \n",
    "    batch_size = 64# 加载测试数据\n",
    "    test_generator = gen.flow_from_directory(\n",
    "        os.path.join(dir, 'test'),\n",
    "        target_size=image_size,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None  # 不使用标签\n",
    "    )\n",
    "\n",
    "    # 计算预测步骤数\n",
    "    steps = math.ceil(test_generator.samples / batch_size)\n",
    "\n",
    "    # 预测测试数据\n",
    "    test = model.predict(test_generator, steps=steps)\n",
    "    print(\"test shape: {}\".format(test.shape))\n",
    "\n",
    "    # 将预测结果保存到文件\n",
    "    print(\"begin create database {}\".format(MODEL.__name__))\n",
    "    with h5py.File(os.path.join(\"models\", tag, \"bottleneck_{}_test.h5\".format(MODEL.__name__)), 'w') as h:\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "\n",
    "    print(\"write_gap_test {} succeeded\".format(MODEL.__name__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3ff5c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Asked to retrieve element 0, but the Sequence has length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwrite_gap_test\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinetune\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mResNet50\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresnet50_weight_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m240\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [80], line 35\u001b[0m, in \u001b[0;36mwrite_gap_test\u001b[1;34m(tag, MODEL, weight_file, image_size, lambda_func, featurewise_std_normalization)\u001b[0m\n\u001b[0;32m     32\u001b[0m steps \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(test_generator\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m/\u001b[39m batch_size)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# 预测测试数据\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest shape: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(test\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# 将预测结果保存到文件\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:103\u001b[0m, in \u001b[0;36mIterator.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 103\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to retrieve element \u001b[39m\u001b[38;5;132;01m{idx}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut the Sequence \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas length \u001b[39m\u001b[38;5;132;01m{length}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx\u001b[38;5;241m=\u001b[39midx, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m    107\u001b[0m         )\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m         np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_batches_seen)\n",
      "\u001b[1;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"
     ]
    }
   ],
   "source": [
    "write_gap_test(\"finetune\", ResNet50, resnet50_weight_file, (240, 320))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
